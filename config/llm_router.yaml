# LLM Router Configuration
# File: config/llm_router.yaml
# Created: 2025-07-17
# Purpose: Configuration for dynamic LLM model selection

providers:
  openai:
    api_base: "https://api.openai.com/v1"
    api_key_path: "OPENAI_API_KEY"
    models:
      gpt-4o:
        name: "gpt-4o"
        cost_per_1k_tokens:
          input: 0.005
          output: 0.015
        max_tokens: 16384
        quality_rating: 9
        use_cases: ["resume_analysis", "complex_qa", "evaluations"]
      
      gpt-4-turbo:
        name: "gpt-4-turbo"
        cost_per_1k_tokens:
          input: 0.01
          output: 0.03
        max_tokens: 16384
        quality_rating: 8
        use_cases: ["resume_optimization", "cover_letters", "detailed_analysis"]
      
      gpt-3.5-turbo:
        name: "gpt-3.5-turbo"
        cost_per_1k_tokens:
          input: 0.0015
          output: 0.002
        max_tokens: 16384
        quality_rating: 6
        use_cases: ["simple_questions", "basic_summarization", "default"]
    
    embeddings:
      text-embedding-3-small:
        dimensions: 1536
        cost_per_1k_tokens: 0.00002

  anthropic:
    api_base: "https://api.anthropic.com"
    api_key_path: "ANTHROPIC_API_KEY"
    models:
      claude-3-5-sonnet-20241022:
        name: "claude-3-5-sonnet-20241022"
        cost_per_1k_tokens:
          input: 0.003
          output: 0.015
        max_tokens: 8192
        quality_rating: 8.5
        use_cases: ["behavioral_questions", "complex_analysis", "creative_writing"]
      
      claude-3-5-haiku-20241022:
        name: "claude-3-5-haiku-20241022"
        cost_per_1k_tokens:
          input: 0.0008
          output: 0.004
        max_tokens: 4096
        quality_rating: 7
        use_cases: ["cost_optimization", "simple_tasks", "routing_classifier"]

# Routing Strategy Configuration
routing_strategy:
  # 1. Hard-coded rule-based routing (fastest)
  rules:
    - condition: "task == 'transcribe_audio'"
      target: "openai/whisper-1"
    - condition: "task == 'summarize_resume'"
      target: "openai/gpt-3.5-turbo"
    - condition: "task == 'optimize_resume'"
      target: "openai/gpt-4-turbo"
    - condition: "task == 'evaluate_answer'"
      target: "anthropic/claude-3-5-sonnet-20241022"
  
  # 2. Semantic similarity routing
  semantic:
    task_embeddings:
      - name: "project_analysis"
        embedding: [0.1, 0.2, 0.3, ...]  # Will be populated
        targets: ["openai/gpt-4o"]
      
      - name: "question_evaluation"
        embedding: [0.5, 0.1, 0.8, ...]
        targets: ["anthropic/claude-3-5-sonnet-20241022"]
      
      - name: "resume_generation"
        embedding: [0.3, 0.7, 0.2, ...]
        targets: ["openai/gpt-4-turbo"]
  
  # 3. LLM-as-classifier (fallback)
  classifier:
    model: "anthropic/claude-3-5-haiku-20241022"
    temperature: 0.1
    prompt_file: "./config/router_classifier_prompt.txt"

# Fallback configuration
fallback:
  model: "openai/gpt-3.5-turbo"  # When all else fails
  max_retry_attempts: 3
  retry_delay: 1.0  # seconds

# Cost and performance optimization
optimization:
  cost_threshold: 0.01  # max cost per request
  latency_threshold_ms: 5000
  enable_caching: true
  cache_ttl: 3600  # seconds

# Debug configuration
debug:
  log_routing_decisions: true
  log_cost_tracking: true
  log_latency: true