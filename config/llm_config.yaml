# TechCoach LLM Configuration
# Simple single-provider configuration using LangChain

# Choose one provider: kimi, openai, claude, gemini, deepseek
provider: "kimi"

# Provider-specific configuration
providers:
  kimi:
    api_key: null  # Set your Kimi API key here or use KIMI_API_KEY env var
    model: "kimi-k2-0711-preview"
    api_base: "https://api.moonshot.cn/v1"
    
  openai:
    api_key: null  # Set your OpenAI API key here or use OPENAI_API_KEY env var
    model: "gpt-4o"
    api_base: "https://api.openai.com/v1"
    
  claude:
    api_key: null  # Set your Claude API key here or use ANTHROPIC_API_KEY env var
    model: "claude-3-5-sonnet-20241022"
    api_base: "https://api.anthropic.com/v1/messages"
    
  gemini:
    api_key: null  # Set your Gemini API key here or use GEMINI_API_KEY env var
    model: "gemini-pro"
    api_base: "https://generativelanguage.googleapis.com/v1beta"
    
  deepseek:
    api_key: null  # Set your DeepSeek API key here or use DEEPSEEK_API_KEY env var
    model: "deepseek-chat"
    api_base: "https://api.deepseek.com/v1"

# Model settings
temperature: 0.7
max_tokens: 2000